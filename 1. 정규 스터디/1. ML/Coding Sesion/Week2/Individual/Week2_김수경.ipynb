{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Week2_김수경.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Bzg_D2sFG-MV","outputId":"cc42be70-2da6-46b9-b19e-6cc9ee7704c2"},"source":["#데이터 준비과정\n","import pandas as pd\n","import numpy as np\n","\n","#Warning이 가독성에 방해되서 제거\n","import warnings\n","warnings.filterwarnings(action='ignore')\n","\n","# 데이터 불러오기. y값은 이미 범주형으로 되어있음.\n","dat_wine=pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/'\n","                     'wine/wine.data',header=None)\n","dat_wine.columns = ['class label', 'alchohol', 'malic acid', 'ash', \n","                    'alcalinity of ash', 'magnesium', 'total phenols', \n","                    'flavanoids', 'nonflavanoid phenols', \n","                    'proanthocyanins', 'color intensity', 'hue', \n","                    'OD208', 'proline']  # Column names\n","print('class label:', np.unique(dat_wine['class label']))  # Class 출력\n","\n","dat_wine.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["class label: [1 2 3]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class label</th>\n","      <th>alchohol</th>\n","      <th>malic acid</th>\n","      <th>ash</th>\n","      <th>alcalinity of ash</th>\n","      <th>magnesium</th>\n","      <th>total phenols</th>\n","      <th>flavanoids</th>\n","      <th>nonflavanoid phenols</th>\n","      <th>proanthocyanins</th>\n","      <th>color intensity</th>\n","      <th>hue</th>\n","      <th>OD208</th>\n","      <th>proline</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>14.23</td>\n","      <td>1.71</td>\n","      <td>2.43</td>\n","      <td>15.6</td>\n","      <td>127</td>\n","      <td>2.80</td>\n","      <td>3.06</td>\n","      <td>0.28</td>\n","      <td>2.29</td>\n","      <td>5.64</td>\n","      <td>1.04</td>\n","      <td>3.92</td>\n","      <td>1065</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>13.20</td>\n","      <td>1.78</td>\n","      <td>2.14</td>\n","      <td>11.2</td>\n","      <td>100</td>\n","      <td>2.65</td>\n","      <td>2.76</td>\n","      <td>0.26</td>\n","      <td>1.28</td>\n","      <td>4.38</td>\n","      <td>1.05</td>\n","      <td>3.40</td>\n","      <td>1050</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>13.16</td>\n","      <td>2.36</td>\n","      <td>2.67</td>\n","      <td>18.6</td>\n","      <td>101</td>\n","      <td>2.80</td>\n","      <td>3.24</td>\n","      <td>0.30</td>\n","      <td>2.81</td>\n","      <td>5.68</td>\n","      <td>1.03</td>\n","      <td>3.17</td>\n","      <td>1185</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>14.37</td>\n","      <td>1.95</td>\n","      <td>2.50</td>\n","      <td>16.8</td>\n","      <td>113</td>\n","      <td>3.85</td>\n","      <td>3.49</td>\n","      <td>0.24</td>\n","      <td>2.18</td>\n","      <td>7.80</td>\n","      <td>0.86</td>\n","      <td>3.45</td>\n","      <td>1480</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>13.24</td>\n","      <td>2.59</td>\n","      <td>2.87</td>\n","      <td>21.0</td>\n","      <td>118</td>\n","      <td>2.80</td>\n","      <td>2.69</td>\n","      <td>0.39</td>\n","      <td>1.82</td>\n","      <td>4.32</td>\n","      <td>1.04</td>\n","      <td>2.93</td>\n","      <td>735</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class label  alchohol  malic acid   ash  alcalinity of ash  magnesium  \\\n","0            1     14.23        1.71  2.43               15.6        127   \n","1            1     13.20        1.78  2.14               11.2        100   \n","2            1     13.16        2.36  2.67               18.6        101   \n","3            1     14.37        1.95  2.50               16.8        113   \n","4            1     13.24        2.59  2.87               21.0        118   \n","\n","   total phenols  flavanoids  nonflavanoid phenols  proanthocyanins  \\\n","0           2.80        3.06                  0.28             2.29   \n","1           2.65        2.76                  0.26             1.28   \n","2           2.80        3.24                  0.30             2.81   \n","3           3.85        3.49                  0.24             2.18   \n","4           2.80        2.69                  0.39             1.82   \n","\n","   color intensity   hue  OD208  proline  \n","0             5.64  1.04   3.92     1065  \n","1             4.38  1.05   3.40     1050  \n","2             5.68  1.03   3.17     1185  \n","3             7.80  0.86   3.45     1480  \n","4             4.32  1.04   2.93      735  "]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"2-rzz9wpG-Mg","outputId":"b2420c35-fec2-4f4a-adf0-114e8a02918a"},"source":["#패키지 설치\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#학습모델이 구하고 싶은 target attribute는 class label이므로 target 변수에 저장\n","y = dat_wine[['class label']]\n","\n","#각 instance를 표한하는 나머지 attribute들은 attributes라는 변수에 저장\n","X = dat_wine[['alchohol', 'malic acid', 'ash', \n","                    'alcalinity of ash', 'magnesium', 'total phenols', \n","                    'flavanoids', 'nonflavanoid phenols', \n","                    'proanthocyanins', 'color intensity', 'hue', \n","                    'OD208', 'proline']]\n","\n","#먼저 EDA를 통해 특성들을 분석해보면 각 특성별로 스케일의 편차가 큰 편이기 때문에 우리가 만든 KNN 모델에서 다른 특성보다 큰 스케일의\n","#특성에 대해 preference가 생긱 것이라 판단해서 정규화를 진행\n","\n","X.describe()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>alchohol</th>\n","      <th>malic acid</th>\n","      <th>ash</th>\n","      <th>alcalinity of ash</th>\n","      <th>magnesium</th>\n","      <th>total phenols</th>\n","      <th>flavanoids</th>\n","      <th>nonflavanoid phenols</th>\n","      <th>proanthocyanins</th>\n","      <th>color intensity</th>\n","      <th>hue</th>\n","      <th>OD208</th>\n","      <th>proline</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","      <td>178.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>13.000618</td>\n","      <td>2.336348</td>\n","      <td>2.366517</td>\n","      <td>19.494944</td>\n","      <td>99.741573</td>\n","      <td>2.295112</td>\n","      <td>2.029270</td>\n","      <td>0.361854</td>\n","      <td>1.590899</td>\n","      <td>5.058090</td>\n","      <td>0.957449</td>\n","      <td>2.611685</td>\n","      <td>746.893258</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>0.811827</td>\n","      <td>1.117146</td>\n","      <td>0.274344</td>\n","      <td>3.339564</td>\n","      <td>14.282484</td>\n","      <td>0.625851</td>\n","      <td>0.998859</td>\n","      <td>0.124453</td>\n","      <td>0.572359</td>\n","      <td>2.318286</td>\n","      <td>0.228572</td>\n","      <td>0.709990</td>\n","      <td>314.907474</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>11.030000</td>\n","      <td>0.740000</td>\n","      <td>1.360000</td>\n","      <td>10.600000</td>\n","      <td>70.000000</td>\n","      <td>0.980000</td>\n","      <td>0.340000</td>\n","      <td>0.130000</td>\n","      <td>0.410000</td>\n","      <td>1.280000</td>\n","      <td>0.480000</td>\n","      <td>1.270000</td>\n","      <td>278.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>12.362500</td>\n","      <td>1.602500</td>\n","      <td>2.210000</td>\n","      <td>17.200000</td>\n","      <td>88.000000</td>\n","      <td>1.742500</td>\n","      <td>1.205000</td>\n","      <td>0.270000</td>\n","      <td>1.250000</td>\n","      <td>3.220000</td>\n","      <td>0.782500</td>\n","      <td>1.937500</td>\n","      <td>500.500000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>13.050000</td>\n","      <td>1.865000</td>\n","      <td>2.360000</td>\n","      <td>19.500000</td>\n","      <td>98.000000</td>\n","      <td>2.355000</td>\n","      <td>2.135000</td>\n","      <td>0.340000</td>\n","      <td>1.555000</td>\n","      <td>4.690000</td>\n","      <td>0.965000</td>\n","      <td>2.780000</td>\n","      <td>673.500000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>13.677500</td>\n","      <td>3.082500</td>\n","      <td>2.557500</td>\n","      <td>21.500000</td>\n","      <td>107.000000</td>\n","      <td>2.800000</td>\n","      <td>2.875000</td>\n","      <td>0.437500</td>\n","      <td>1.950000</td>\n","      <td>6.200000</td>\n","      <td>1.120000</td>\n","      <td>3.170000</td>\n","      <td>985.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>14.830000</td>\n","      <td>5.800000</td>\n","      <td>3.230000</td>\n","      <td>30.000000</td>\n","      <td>162.000000</td>\n","      <td>3.880000</td>\n","      <td>5.080000</td>\n","      <td>0.660000</td>\n","      <td>3.580000</td>\n","      <td>13.000000</td>\n","      <td>1.710000</td>\n","      <td>4.000000</td>\n","      <td>1680.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         alchohol  malic acid         ash  alcalinity of ash   magnesium  \\\n","count  178.000000  178.000000  178.000000         178.000000  178.000000   \n","mean    13.000618    2.336348    2.366517          19.494944   99.741573   \n","std      0.811827    1.117146    0.274344           3.339564   14.282484   \n","min     11.030000    0.740000    1.360000          10.600000   70.000000   \n","25%     12.362500    1.602500    2.210000          17.200000   88.000000   \n","50%     13.050000    1.865000    2.360000          19.500000   98.000000   \n","75%     13.677500    3.082500    2.557500          21.500000  107.000000   \n","max     14.830000    5.800000    3.230000          30.000000  162.000000   \n","\n","       total phenols  flavanoids  nonflavanoid phenols  proanthocyanins  \\\n","count     178.000000  178.000000            178.000000       178.000000   \n","mean        2.295112    2.029270              0.361854         1.590899   \n","std         0.625851    0.998859              0.124453         0.572359   \n","min         0.980000    0.340000              0.130000         0.410000   \n","25%         1.742500    1.205000              0.270000         1.250000   \n","50%         2.355000    2.135000              0.340000         1.555000   \n","75%         2.800000    2.875000              0.437500         1.950000   \n","max         3.880000    5.080000              0.660000         3.580000   \n","\n","       color intensity         hue       OD208      proline  \n","count       178.000000  178.000000  178.000000   178.000000  \n","mean          5.058090    0.957449    2.611685   746.893258  \n","std           2.318286    0.228572    0.709990   314.907474  \n","min           1.280000    0.480000    1.270000   278.000000  \n","25%           3.220000    0.782500    1.937500   500.500000  \n","50%           4.690000    0.965000    2.780000   673.500000  \n","75%           6.200000    1.120000    3.170000   985.000000  \n","max          13.000000    1.710000    4.000000  1680.000000  "]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"2_ZNpZyaG-Mi"},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=64)\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import GridSearchCV\n","knn_clf = KNeighborsClassifier()\n","params = {'weights':['uniform','distance'], 'n_neighbors':[3,4,5]}\n","grid_search = GridSearchCV(knn_clf, param_grid=params, cv=5, verbose=0, scoring='f1')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":false,"id":"H2o6QLR0G-Mk","outputId":"94a7dffb-6243-4c3b-b702-f5ac019cf66b"},"source":["grid_search.fit(X_train,y_train)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n","             param_grid={'n_neighbors': [3, 4, 5],\n","                         'weights': ['uniform', 'distance']},\n","             scoring='f1')"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"9Fzp6EfEG-Ml","outputId":"117f4158-0672-44fc-a644-3377e086d367"},"source":["grid_search.best_params_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'n_neighbors': 3, 'weights': 'uniform'}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"u-tOFCAKG-Mm","outputId":"f5e4ad2a-360d-4d46-fa77-b54f5f302ca7"},"source":["grid_search.best_score_"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["nan"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"a0xNu3d6G-Mn","outputId":"4072a86d-0ca6-406e-92a6-6b11b94f6c12"},"source":["import sklearn.metrics as mt\n","y_pred = grid_search.predict(X_test)\n","f1_score=mt.f1_score(y_test,y_pred)\n","matrix=mt.confusion_matrix(y_test,y_pred)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m<ipython-input-21-91c5b37dc83e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1066\u001b[0m     \u001b[0mmodified\u001b[0m \u001b[1;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \"\"\"\n\u001b[1;32m-> 1068\u001b[1;33m     return fbeta_score(y_true, y_pred, beta=1, labels=labels,\n\u001b[0m\u001b[0;32m   1069\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \"\"\"\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m     _, _, f, _ = precision_recall_fscore_support(y_true, y_pred,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                  \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m                                                  \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0m\u001b[0;32m   1462\u001b[0m                                     pos_label)\n\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1289\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m                 \u001b[0maverage_options\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'samples'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[0m\u001b[0;32m   1292\u001b[0m                              \u001b[1;34m\"choose another average setting, one of %r.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m                              % (y_type, average_options))\n","\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."]}]},{"cell_type":"code","metadata":{"id":"uNEUqZe0G-Mp"},"source":[""],"execution_count":null,"outputs":[]}]}